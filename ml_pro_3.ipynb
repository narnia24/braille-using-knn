{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIfs4nHzO7R/CDqYtKDDpR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Tq0vo-gfPx",
        "outputId": "41ba11f2-d312-41ac-c0e5-80139734a842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No images found. Please verify the dataset structure and file types.\n",
            "No images loaded. Please check the dataset path and file structure.\n",
            "No data available for training. Exiting...\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gtts import gTTS\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Path to the dataset (update this if needed)\n",
        "dataset_path = Path(\"/root/.cache/kagglehub/datasets/shanks0465/braille-character-dataset/versions/1\")\n",
        "\n",
        "# Load the dataset: Traverse the directory and find all image files\n",
        "image_files = []\n",
        "for subdir, _, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_files.append(os.path.join(subdir, file))\n",
        "\n",
        "# Verify if images were found\n",
        "if image_files:\n",
        "    print(f\"Loaded {len(image_files)} images\")\n",
        "else:\n",
        "    print(\"No images found. Please verify the dataset structure and file types.\")\n",
        "\n",
        "# Function to load and preprocess the dataset\n",
        "def load_data(dataset_path):\n",
        "    X = []\n",
        "    y = []\n",
        "    allowed_extensions = ['.png', '.jpg', '.jpeg']\n",
        "\n",
        "    # Traverse the dataset folder\n",
        "    for subdir, _, files in os.walk(dataset_path):\n",
        "        for img_file in files:\n",
        "            img_path = os.path.join(subdir, img_file)\n",
        "            # Check if it's an image\n",
        "            if any(img_file.lower().endswith(ext) for ext in allowed_extensions):\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Warning: Could not load image {img_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Labeling: Assuming the subdirectory name is the label (you can adjust this)\n",
        "                label = subdir.split('/')[-1].lower()  # Use the folder name as the label\n",
        "\n",
        "                # Preprocess image: Resize and flatten\n",
        "                img = cv2.resize(img, (28, 28))  # Resize image to 28x28\n",
        "                img = img.flatten()  # Flatten the image to a 1D array\n",
        "                X.append(img)\n",
        "                y.append(label)\n",
        "            else:\n",
        "                print(f\"Skipping non-image file: {img_path}\")\n",
        "\n",
        "    # Ensure data is loaded\n",
        "    if len(X) == 0:\n",
        "        print(\"No images loaded. Please check the dataset path and file structure.\")\n",
        "    else:\n",
        "        print(f\"Loaded {len(X)} images\")\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the dataset\n",
        "X, y = load_data(dataset_path)\n",
        "\n",
        "# Proceed if data was successfully loaded\n",
        "if X.shape[0] > 0:\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize classifiers\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Combine the classifiers into an ensemble using Voting Classifier\n",
        "    voting_clf = VotingClassifier(estimators=[('knn', knn), ('dt', decision_tree)], voting='hard')\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions using the ensemble model\n",
        "    y_pred = voting_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Ensemble Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Convert the prediction to speech using gTTS\n",
        "    def text_to_speech(text, output_file=\"output.mp3\"):\n",
        "        tts = gTTS(text=text, lang='en', slow=False)\n",
        "        tts.save(output_file)\n",
        "        print(f\"Speech saved to {output_file}\")\n",
        "\n",
        "    # Test the model with a sample image\n",
        "    test_image = X_test[0]\n",
        "    predicted_text = voting_clf.predict([test_image])[0]\n",
        "    print(f\"Predicted Braille symbol: {predicted_text}\")\n",
        "\n",
        "    # Convert the predicted text to speech and save the audio\n",
        "    text_to_speech(predicted_text, output_file=\"output.mp3\")\n",
        "\n",
        "    # Display the audio output\n",
        "    display(Audio('output.mp3'))\n",
        "else:\n",
        "    print(\"No data available for training. Exiting...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTD35V8OgzxG",
        "outputId": "170cd959-b4c4-497d-c0b5-2c9cf4dd232f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ]
    }
  ]
}